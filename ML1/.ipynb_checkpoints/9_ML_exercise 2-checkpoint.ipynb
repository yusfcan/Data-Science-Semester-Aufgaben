{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Woche 9: Machine Learning 1 - Übung am eigenen Projekt\n",
    "\n",
    "**Ziel dieser Übung:** Nachdem Sie die wichtigsten ML-Konzepte kennengelernt haben, wenden Sie Ihr erstes Machine Learning Modell auf Ihren eigenen bereinigten Datensatz an.\n",
    "\n",
    "**Arbeitsweise:**\n",
    "- Arbeiten Sie die Aufgaben nacheinander durch\n",
    "- Entscheiden Sie zunächst, ob Ihr Problem ein Classification- oder Regression-Problem ist\n",
    "- Nutzen Sie die Code-Zellen für Ihre Implementierung\n",
    "- Orientieren Sie sich an den Beispielen aus den Slides\n",
    "- Evaluieren Sie Ihr Modell und dokumentieren Sie (ganz wichtig!) die Ergebnisse\n",
    "\n",
    "**Wichtig:** Machine Learning ist optional für Ihr Projekt! Wenn Ihr Datensatz oder Ihre Forschungsfrage sich nicht für ML eignet, können Sie diese Woche auch überspringen und sich auf Visualisierungen und Streamlit konzentrieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Bibliotheken importieren und Daten einlesen\n",
    "\n",
    "**Aufgabe:** Importieren Sie die notwendigen Bibliotheken und laden Sie Ihren bereinigten Datensatz aus Woche 7.\n",
    "\n",
    "**Hinweise:**\n",
    "- Importieren Sie: `pandas`, `numpy`, `matplotlib.pyplot`, `seaborn`\n",
    "- Importieren Sie sklearn Module: `train_test_split`, verschiedene Modelle, Metriken\n",
    "- Laden Sie Ihren bereinigten CSV-Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "# Warnungen unterdrücken (optional)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Zufallsseed für Reproduzierbarkeit\n",
    "np.random.seed(42)\n",
    "\n",
    "# Bereinigten Datensatz einlesen\n",
    "# df = pd.read_csv('ihr_datensatz_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Überblick über den Datensatz\n",
    "\n",
    "**Aufgabe:** Verschaffen Sie sich -wie immer- einen Überblick über Ihren Datensatz.\n",
    "\n",
    "**Was Sie prüfen sollten:**\n",
    "- Dimensionen des Datensatzes\n",
    "- Datentypen der Spalten\n",
    "- Statistische Kennzahlen\n",
    "- Erste Zeilen anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionen\n",
    "\n",
    "\n",
    "# Erste Zeilen\n",
    "\n",
    "\n",
    "# Informationen zu Spalten\n",
    "\n",
    "\n",
    "# Statistische Übersicht für numerische Spalten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ML Problem-Typ identifizieren\n",
    "\n",
    "**Aufgabe:** Entscheiden Sie, welchen Typ von ML-Problem Sie lösen möchten. Denken Sie darüber vertieft nach und nehmen Sie sich dafür ruhig mehr Zeit!\n",
    "\n",
    "### Classification (Klassifikation)\n",
    "- **Ziel:** Kategorie vorhersagen\n",
    "- **Beispiele:** \n",
    "  - Mental Health: Depression ja/nein\n",
    "  - Wetter: Regentyp (leicht/mittel/stark)\n",
    "  - Finanzen: Kreditrisiko (niedrig/mittel/hoch)\n",
    "  - Social Media: Sentiment (positiv/negativ/neutral)\n",
    "  - Kosmetik: Produktkategorie\n",
    "  - Astronomie: Objekttyp (Stern/Planet/Galaxie)\n",
    "\n",
    "### Regression\n",
    "- **Ziel:** Kontinuierlichen Wert vorhersagen\n",
    "- **Beispiele:**\n",
    "  - Wetter: Temperatur in °C\n",
    "  - Finanzen: Aktienkurs, Preis\n",
    "  - Social Media: Anzahl Likes/Shares\n",
    "  - Kosmetik: Produktpreis\n",
    "  - Astronomie: Entfernung, Helligkeit\n",
    "  - Mental Health: Depressions-Score (0-100)\n",
    "\n",
    "**Dokumentieren Sie Ihre Entscheidung:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mein ML-Problem:\n",
    "\n",
    "**Problem-Typ:** [Classification / Regression]\n",
    "\n",
    "**Forschungsfrage:**\n",
    "- ...\n",
    "\n",
    "**Target-Variable (y):**\n",
    "- Spaltenname: ...\n",
    "- Typ: ...\n",
    "- Bedeutung: ...\n",
    "\n",
    "**Mögliche Features (X):**\n",
    "- ...\n",
    "- ...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Features (X) und Target (y) definieren\n",
    "\n",
    "**Aufgabe:** Wählen Sie Ihre Features und Target-Variable aus.\n",
    "\n",
    "**Wichtige Hinweise:**\n",
    "- **Features (X):** Sollten numerisch sein (kategoriale Features müssen später encodiert werden)\n",
    "- **Target (y):** \n",
    "  - Bei Classification: Kategoriale Variable (z.B. 'ja'/'nein', 'Typ A'/'Typ B'/'Typ C')\n",
    "  - Bei Regression: Numerische Variable (z.B. Temperatur, Preis, Score)\n",
    "- Beginnen Sie mit 2-5 Features\n",
    "- Entfernen Sie Zeilen mit fehlenden Werten in Features oder Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfen Sie, welche Spalten als Features in Frage kommen\n",
    "# Numerische Spalten:\n",
    "# numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "# print(\"Numerische Spalten:\", list(numeric_cols))\n",
    "\n",
    "# Kategoriale Spalten:\n",
    "# categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "# print(\"Kategoriale Spalten:\", list(categorical_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (X) und Target (y) definieren\n",
    "\n",
    "# Beispiel für Classification:\n",
    "# X = df[['feature1', 'feature2', 'feature3']]\n",
    "# y = df['target_kategorie']\n",
    "\n",
    "# Beispiel für Regression:\n",
    "# X = df[['feature1', 'feature2', 'feature3']]\n",
    "# y = df['target_wert']\n",
    "\n",
    "# Fehlende Werte entfernen\n",
    "# df_model = df[['feature1', 'feature2', 'feature3', 'target']].dropna()\n",
    "# X = df_model[['feature1', 'feature2', 'feature3']]\n",
    "# y = df_model['target']\n",
    "\n",
    "print(f\"Anzahl Samples: {len(X)}\")\n",
    "print(f\"Anzahl Features: {X.shape[1]}\")\n",
    "print(f\"\\nTarget-Verteilung:\")\n",
    "print(y.value_counts())  # Für Classification\n",
    "# print(y.describe())  # Für Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Explorative Datenanalyse (EDA) für ML\n",
    "\n",
    "**Aufgabe:** Untersuchen Sie die Beziehung zwischen Features und Target.\n",
    "\n",
    "**Für Classification:**\n",
    "- Boxplots: Features nach Target-Kategorien\n",
    "- Visualisieren Sie, ob sich die Klassen unterscheiden\n",
    "\n",
    "**Für Regression:**\n",
    "- Scatter Plots: Features vs. Target\n",
    "- Korrelation zwischen Features und Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel für Classification: Boxplots\n",
    "# fig, axes = plt.subplots(1, len(X.columns), figsize=(15, 4))\n",
    "# for i, col in enumerate(X.columns):\n",
    "#     df_model.boxplot(column=col, by='target', ax=axes[i])\n",
    "#     axes[i].set_title(f'{col} nach Target')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel für Regression: Scatter Plots\n",
    "# fig, axes = plt.subplots(1, len(X.columns), figsize=(15, 4))\n",
    "# for i, col in enumerate(X.columns):\n",
    "#     axes[i].scatter(df_model[col], y, alpha=0.5)\n",
    "#     axes[i].set_xlabel(col)\n",
    "#     axes[i].set_ylabel('Target')\n",
    "#     axes[i].set_title(f'{col} vs Target')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Korrelationsmatrix (für Regression)\n",
    "# correlation_matrix = df_model.corr()\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "# plt.title('Korrelationsmatrix')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ihre Beobachtungen:**\n",
    "- Welche Features scheinen am wichtigsten?\n",
    "- Gibt es klare Muster?\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Train/Test Split\n",
    "\n",
    "**Aufgabe:** Teilen Sie Ihre Daten in Trainings- und Testdaten auf.\n",
    "\n",
    "**Warum?** \n",
    "- Training Set (80%): Modell lernt hier\n",
    "- Test Set (20%): Modell wird hier evaluiert\n",
    "- Verhindert Overfitting!\n",
    "\n",
    "**Wichtig:** Testen Sie das Modell NIEMALS auf Trainingsdaten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,      # 20% für Testing\n",
    "    random_state=42     # Reproduzierbarkeit\n",
    ")\n",
    "\n",
    "print(f\"Training Set: {len(X_train)} samples\")\n",
    "print(f\"Test Set: {len(X_test)} samples\")\n",
    "print(f\"\\nTraining Set - Target Verteilung:\")\n",
    "print(y_train.value_counts())  # Für Classification\n",
    "# print(y_train.describe())  # Für Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7A. ML Modelle - CLASSIFICATION\n",
    "\n",
    "**⚠️ Nur für Classification-Probleme! Überspringen Sie diese Sektion, wenn Sie Regression machen.**\n",
    "\n",
    "**Aufgabe:** Trainieren Sie verschiedene Classification-Modelle und vergleichen Sie sie.\n",
    "\n",
    "**Algorithmen zum Ausprobieren:**\n",
    "1. Nearest Centroid Classifier (NCC) - sehr einfach\n",
    "2. K-Nearest Neighbors (KNN) - ähnlich zu NCC, aber flexibler\n",
    "3. Decision Tree - findet Regeln automatisch\n",
    "4. Logistic Regression - trotz Namen für Classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Algorithmen importieren\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Nearest Centroid Classifier\n",
    "print(\"=== Nearest Centroid Classifier ===\")\n",
    "ncc = NearestCentroid()\n",
    "ncc.fit(X_train, y_train)\n",
    "y_pred_ncc = ncc.predict(X_test)\n",
    "accuracy_ncc = accuracy_score(y_test, y_pred_ncc)\n",
    "print(f\"Accuracy: {accuracy_ncc:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. K-Nearest Neighbors\n",
    "print(\"=== K-Nearest Neighbors (KNN) ===\")\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"Accuracy: {accuracy_knn:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Decision Tree\n",
    "print(\"=== Decision Tree ===\")\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "print(f\"Accuracy: {accuracy_tree:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Logistic Regression\n",
    "print(\"=== Logistic Regression ===\")\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "print(f\"Accuracy: {accuracy_logreg:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellvergleich\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Nearest Centroid', 'KNN', 'Decision Tree', 'Logistic Regression'],\n",
    "    'Accuracy': [accuracy_ncc, accuracy_knn, accuracy_tree, accuracy_logreg]\n",
    "})\n",
    "results = results.sort_values('Accuracy', ascending=False)\n",
    "print(\"\\n=== Modellvergleich ===\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# Visualisierung\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(results['Model'], results['Accuracy'])\n",
    "plt.title('Modellvergleich - Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(results['Accuracy']):\n",
    "    plt.text(i, v + 0.02, f'{v:.2%}', ha='center')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7B. ML Modelle - REGRESSION\n",
    "\n",
    "**⚠️ Nur für Regression-Probleme! Überspringen Sie diese Sektion, wenn Sie Classification gemacht haben.**\n",
    "\n",
    "**Aufgabe:** Trainieren Sie verschiedene Regression-Modelle und vergleichen Sie sie.\n",
    "\n",
    "**Algorithmen zum Ausprobieren:**\n",
    "1. Linear Regression - einfache Gerade\n",
    "2. K-Nearest Neighbors Regressor - Nachbarn-Durchschnitt\n",
    "3. Decision Tree Regressor - findet nicht-lineare Muster\n",
    "4. Random Forest Regressor - viele Bäume = robuster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Algorithmen importieren\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Linear Regression\n",
    "print(\"=== Linear Regression ===\")\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "print(f\"RMSE: {rmse_lr:.2f}\")\n",
    "print(f\"R² Score: {r2_lr:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. K-Nearest Neighbors Regressor\n",
    "print(\"=== K-Nearest Neighbors Regressor ===\")\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_reg.fit(X_train, y_train)\n",
    "y_pred_knn = knn_reg.predict(X_test)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "rmse_knn = np.sqrt(mse_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "print(f\"RMSE: {rmse_knn:.2f}\")\n",
    "print(f\"R² Score: {r2_knn:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Decision Tree Regressor\n",
    "print(\"=== Decision Tree Regressor ===\")\n",
    "tree_reg = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "y_pred_tree = tree_reg.predict(X_test)\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "rmse_tree = np.sqrt(mse_tree)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "print(f\"RMSE: {rmse_tree:.2f}\")\n",
    "print(f\"R² Score: {r2_tree:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Random Forest Regressor\n",
    "print(\"=== Random Forest Regressor ===\")\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f\"RMSE: {rmse_rf:.2f}\")\n",
    "print(f\"R² Score: {r2_rf:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellvergleich\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'KNN Regressor', 'Decision Tree', 'Random Forest'],\n",
    "    'RMSE': [rmse_lr, rmse_knn, rmse_tree, rmse_rf],\n",
    "    'R² Score': [r2_lr, r2_knn, r2_tree, r2_rf]\n",
    "})\n",
    "results = results.sort_values('R² Score', ascending=False)\n",
    "print(\"\\n=== Modellvergleich ===\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# Visualisierung\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# RMSE\n",
    "ax1.bar(results['Model'], results['RMSE'])\n",
    "ax1.set_title('Modellvergleich - RMSE (niedriger = besser)')\n",
    "ax1.set_ylabel('RMSE')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# R² Score\n",
    "ax2.bar(results['Model'], results['R² Score'])\n",
    "ax2.set_title('Modellvergleich - R² Score (höher = besser)')\n",
    "ax2.set_ylabel('R² Score')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(results['R² Score']):\n",
    "    ax2.text(i, v + 0.02, f'{v:.2%}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Detaillierte Evaluation - Classification\n",
    "\n",
    "**⚠️ Nur für Classification!**\n",
    "\n",
    "**Aufgabe:** Analysieren Sie das beste Modell genauer.\n",
    "\n",
    "**Metriken:**\n",
    "- **Accuracy:** Anteil korrekter Vorhersagen\n",
    "- **Confusion Matrix:** Welche Fehler macht das Modell?\n",
    "- **Classification Report:** Precision, Recall, F1-Score pro Klasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wählen Sie Ihr bestes Modell aus Sektion 7A\n",
    "# best_model = knn  # Beispiel\n",
    "# y_pred_best = y_pred_knn\n",
    "\n",
    "# Classification Report\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation der Confusion Matrix:**\n",
    "- Diagonale: Korrekte Vorhersagen\n",
    "- Außerhalb der Diagonalen: Fehler\n",
    "- Welche Klassen werden am häufigsten verwechselt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Detaillierte Evaluation - Regression\n",
    "\n",
    "**⚠️ Nur für Regression!**\n",
    "\n",
    "**Aufgabe:** Analysieren Sie das beste Modell genauer.\n",
    "\n",
    "**Metriken:**\n",
    "- **RMSE (Root Mean Squared Error):** Durchschnittlicher Fehler (in gleicher Einheit wie Target)\n",
    "- **R² Score:** Wie gut erklärt das Modell die Varianz? (0-1, höher = besser)\n",
    "- **Residual Plot:** Visualisierung der Fehler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wählen Sie Ihr bestes Modell aus Sektion 7B\n",
    "# best_model = rf  # Beispiel\n",
    "# y_pred_best = y_pred_rf\n",
    "\n",
    "# Alle Metriken\n",
    "mse = mean_squared_error(y_test, y_pred_best)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred_best)\n",
    "r2 = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"=== Evaluation Metriken ===\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R² Score: {r2:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung: Predicted vs. Actual\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot 1: Predicted vs Actual\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Tatsächliche Werte')\n",
    "plt.ylabel('Vorhergesagte Werte')\n",
    "plt.title('Predicted vs Actual')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals (Fehler)\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y_test - y_pred_best\n",
    "plt.scatter(y_pred_best, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "plt.xlabel('Vorhergesagte Werte')\n",
    "plt.ylabel('Residuals (Fehler)')\n",
    "plt.title('Residual Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "- **Predicted vs Actual:** Punkte sollten nahe der roten Linie liegen\n",
    "- **Residual Plot:** Fehler sollten zufällig um 0 verteilt sein (kein Muster!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Feature Importance (Optional)\n",
    "\n",
    "**Aufgabe:** Finden Sie heraus, welche Features am wichtigsten sind.\n",
    "\n",
    "**Hinweis:** Funktioniert nur für Decision Trees und Random Forests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance für Decision Tree oder Random Forest\n",
    "# Wählen Sie Ihr Tree-basiertes Modell:\n",
    "# model_with_importance = tree  # oder rf, tree_reg, etc.\n",
    "\n",
    "# importances = model_with_importance.feature_importances_\n",
    "# feature_importance_df = pd.DataFrame({\n",
    "#     'Feature': X.columns,\n",
    "#     'Importance': importances\n",
    "# }).sort_values('Importance', ascending=False)\n",
    "\n",
    "# print(\"=== Feature Importance ===\")\n",
    "# print(feature_importance_df.to_string(index=False))\n",
    "\n",
    "# Visualisierung\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "# plt.xlabel('Importance')\n",
    "# plt.title('Feature Importance')\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.grid(axis='x', alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Vorhersagen auf neuen Daten\n",
    "\n",
    "**Aufgabe:** Machen Sie Vorhersagen für neue, hypothetische Datenpunkte. Sie können z.B. per genAI neue Daten\n",
    "\n",
    "**Hinweis:** Dies zeigt, wie Ihr Modell in der Praxis verwendet werden könnte!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: Neue Datenpunkte definieren\n",
    "# new_data = pd.DataFrame({\n",
    "#     'feature1': [wert1],\n",
    "#     'feature2': [wert2],\n",
    "#     'feature3': [wert3]\n",
    "# })\n",
    "\n",
    "# Vorhersage mit bestem Modell\n",
    "# prediction = best_model.predict(new_data)\n",
    "# print(f\"Vorhersage für neue Daten: {prediction[0]}\")\n",
    "\n",
    "# Für Classification: Wahrscheinlichkeiten anzeigen\n",
    "# if hasattr(best_model, 'predict_proba'):\n",
    "#     probabilities = best_model.predict_proba(new_data)\n",
    "#     print(f\"Wahrscheinlichkeiten: {probabilities[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Reflexion und Dokumentation\n",
    "\n",
    "**Dokumentieren Sie Ihre Arbeit:**\n",
    "\n",
    "Beantworten Sie folgende Fragen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ihre Reflexion:\n",
    "\n",
    "**1. Problem-Typ und Forschungsfrage:**\n",
    "   - Welches Problem haben Sie gelöst (Classification/Regression)?\n",
    "   - Wie lautete Ihre Forschungsfrage?\n",
    "   - ...\n",
    "\n",
    "**2. Features und Target:**\n",
    "   - Welche Features haben Sie verwendet?\n",
    "   - Warum haben Sie diese Features gewählt?\n",
    "   - Was ist Ihre Target-Variable?\n",
    "   - ...\n",
    "\n",
    "**3. Modellvergleich:**\n",
    "   - Welches Modell hat am besten performt?\n",
    "   - Wie gut ist die Performance (Accuracy/R²)?\n",
    "   - Überrascht Sie das Ergebnis?\n",
    "   - ...\n",
    "\n",
    "**4. Interpretation:**\n",
    "   - Welche Features sind am wichtigsten?\n",
    "   - Macht das Sinn für Ihr Problem?\n",
    "   - Welche Fehler macht das Modell?\n",
    "   - ...\n",
    "\n",
    "**5. Herausforderungen:**\n",
    "   - Welche Schwierigkeiten gab es?\n",
    "   - Wie haben Sie diese gelöst?\n",
    "   - Was würden Sie beim nächsten Mal anders machen?\n",
    "   - ...\n",
    "\n",
    "**6. Nächste Schritte:**\n",
    "   - Wie könnten Sie das Modell verbessern?\n",
    "   - Mehr Features? Besseres Feature Engineering?\n",
    "   - Andere Algorithmen?\n",
    "   - Werden Sie ML in Ihrer Streamlit-App verwenden?\n",
    "   - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Modell speichern (Optional)\n",
    "\n",
    "**Aufgabe:** Speichern Sie Ihr bestes Modell, um es später in Streamlit zu verwenden.\n",
    "\n",
    "**Hinweis:** Dies ist optional! Sie können auch direkt in Streamlit ein neues Modell trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell speichern mit pickle\n",
    "# import pickle\n",
    "\n",
    "# with open('best_model.pkl', 'wb') as f:\n",
    "#     pickle.dump(best_model, f)\n",
    "\n",
    "# print(\"Modell wurde gespeichert!\")\n",
    "\n",
    "# Später laden:\n",
    "# with open('best_model.pkl', 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Zusammenfassung\n",
    "\n",
    "**Sie haben in dieser Übung:**\n",
    "- ✅ Ihr ML-Problem identifiziert (Classification/Regression)\n",
    "- ✅ Features und Target definiert\n",
    "- ✅ Train/Test Split durchgeführt\n",
    "- ✅ Mehrere ML-Algorithmen trainiert und verglichen\n",
    "- ✅ Das beste Modell evaluiert\n",
    "- ✅ Feature Importance analysiert (optional)\n",
    "- ✅ Vorhersagen auf neuen Daten gemacht\n",
    "\n",
    "**Nächste Woche (Woche 10):**\n",
    "- Machine Learning 2: Fortgeschrittene Evaluation\n",
    "- Streamlit Einführung: Erste Web-App erstellen\n",
    "\n",
    "**Tipp für Streamlit:**\n",
    "- Nicht jedes Projekt braucht ML!\n",
    "- Visualisierungen und explorative Analysen sind oft wertvoller\n",
    "- Falls ML passt: Integrieren Sie Vorhersagen in Ihre App"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
